{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593cb571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "CELL_LENGTH_M=7.5\n",
    "TIME_STEP_S=1.6\n",
    "print(f\"Stae fizyczne: Dugo kom贸rki = {CELL_LENGTH_M} m, Krok czasu = {TIME_STEP_S} s\")\n",
    "\n",
    "# --- Ustawienia Wykres贸w ---\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8) # Domylnie wiksze wykresy\n",
    "print(\"\\nUstawiono style wykres贸w. Kom贸rka 1 gotowa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konfiguracja globalna\n",
    "TARGET_RECORDING_ID = \"05\"\n",
    "print(f\"TARGET_RECORDING_ID = '{TARGET_RECORDING_ID}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d017c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_aggregate_exid(data_dir, rec_ids):\n",
    "    \"\"\"\n",
    "    aduje i czy dane trajektorii z wielu nagra ExiD.\n",
    "    \"\"\"\n",
    "    all_tracks = []\n",
    "    \n",
    "    for rec_id in rec_ids:\n",
    "        tracks_path = f'{data_dir}{rec_id}_tracks.csv'\n",
    "        meta_path = f'{data_dir}{rec_id}_tracksMeta.csv'\n",
    "\n",
    "        try:\n",
    "            tracks = pd.read_csv(tracks_path, low_memory=False)\n",
    "            tracks_meta = pd.read_csv(meta_path, low_memory=False)\n",
    "\n",
    "            required_meta_cols = ['trackId', 'class', 'width'] \n",
    "            available_meta_cols = [col for col in required_meta_cols if col in tracks_meta.columns]\n",
    "            \n",
    "            tracks = pd.merge(tracks, tracks_meta[available_meta_cols], on='trackId', how='left')\n",
    "            \n",
    "            # Oblicz cakowit prdko w m/s\n",
    "            tracks['speed_m_s'] = np.sqrt(tracks['xVelocity']**2 + tracks['yVelocity']**2)\n",
    "            \n",
    "            # Zapisz ID nagrania\n",
    "            tracks['recordingId'] = rec_id\n",
    "            \n",
    "            all_tracks.append(tracks)\n",
    "            print(f\"Zaadowano nagranie ID: {rec_id}. Pojazd贸w: {len(tracks['trackId'].unique())}\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Ostrze偶enie: Nie znaleziono plik贸w dla nagrania ID: {rec_id}. Pomijam.\")\n",
    "        except KeyError as e:\n",
    "            print(f\"Ostrze偶enie: Bd kolumny w nagraniu ID: {rec_id}: {e}. Pomijam.\")\n",
    "\n",
    "    if not all_tracks:\n",
    "        return None, None\n",
    "        \n",
    "    return pd.concat(all_tracks, ignore_index=True), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ef4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wczytywanie danych...\")\n",
    "\n",
    "rec_ids_do_analizy = [f\"{i:02}\" for i in range(0, 38)] \n",
    "print(f\"Nagrania do analizy: {rec_ids_do_analizy}\")\n",
    "\n",
    "data_path = \"../data/data/\"\n",
    "\n",
    "try:\n",
    "    tracks_df, _ = load_and_aggregate_exid(data_dir=data_path, \n",
    "                                           rec_ids=rec_ids_do_analizy)\n",
    "    \n",
    "    if tracks_df is not None:\n",
    "        print(f\"\\nWczytano {len(tracks_df)} pomiar贸w\")\n",
    "        print(f\"Dostpne nagrania: {tracks_df['recordingId'].unique()}\")\n",
    "        print(\"\\nPierwsze wiersze:\")\n",
    "        print(tracks_df.head())\n",
    "    else:\n",
    "        print(\"Bd: nie wczytano danych\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Nie znaleziono plik贸w w {data_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Bd podczas wczytywania: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110aa7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weryfikacja kork贸w...\")\n",
    "\n",
    "if 'tracks_df' in locals() and tracks_df is not None:\n",
    "    tracks_df['s_center'] = tracks_df['traveledDistance']\n",
    "\n",
    "    unique_ids = sorted(tracks_df['recordingId'].unique())\n",
    "    num_ids = len(unique_ids)\n",
    "\n",
    "    cols = 4\n",
    "    rows = (num_ids + cols - 1) // cols \n",
    "\n",
    "    print(f\"\\nZnaleziono {num_ids} nagra do wizualizacji.\")\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows), sharex=True, sharey=True)\n",
    "    ax_flat = axes.flat\n",
    "\n",
    "    # U偶ywamy zmiennej iteracyjnej 'i' do poprawnego ukrycia pustych osi\n",
    "    i = 0\n",
    "    for rec_id in unique_ids:\n",
    "        ax = ax_flat[i] \n",
    "        df_rec = tracks_df[tracks_df['recordingId'] == rec_id]\n",
    "        \n",
    "        if df_rec.empty:\n",
    "            ax.set_title(f\"Nagranie {rec_id} (brak danych)\")\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # U偶ycie mniejszej pr贸bki dla wydajnoci\n",
    "        sample_rec_df = df_rec.sample(frac=0.05, random_state=42)\n",
    "        \n",
    "        # *** U偶ywamy 's_center' (czyli 'traveledDistance') ***\n",
    "        sns.scatterplot(data=sample_rec_df, x='s_center', y='lonVelocity',\n",
    "                        s=3, alpha=0.3, ax=ax, legend=False)\n",
    "        \n",
    "        ax.set_title(f\"Nagranie {rec_id}\")\n",
    "        ax.set_xlabel('Pozycja [m]', fontsize=9)\n",
    "        ax.set_ylabel('Prdko [m/s]', fontsize=9)\n",
    "        \n",
    "        i += 1 # Inkrementacja indeksu po udanym wykresie\n",
    "\n",
    "    # Ukrywanie pustych podwykres贸w\n",
    "    for j in range(i, len(ax_flat)):\n",
    "        ax_flat[j].set_visible(False)\n",
    "        \n",
    "    # Ustawienie limit贸w osi X i Y\n",
    "    plt.xlim(0, tracks_df['s_center'].max() * 1.05 if not tracks_df['s_center'].empty else 1100) \n",
    "    plt.ylim(-1, 40) \n",
    "    plt.suptitle('Prdko vs Pozycja', fontsize=18, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Brak danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mapa geometrii...\")\n",
    "\n",
    "if 'tracks_df' in locals() and tracks_df is not None:\n",
    "    sample_df = tracks_df.sample(frac=0.05, random_state=42)\n",
    "    print(f\"Wizualizacja dla {len(sample_df)} punkt贸w\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    sns.scatterplot(data=sample_df, x='xCenter', y='yCenter', \n",
    "    # sns.scatterplot(data=sample_df, x='s_center', y='latLaneCenterOffset', \n",
    "                    hue='laneletId', palette='tab20', s=1, legend=False)\n",
    "    \n",
    "    plt.title('Wizualizacja segment贸w drogi', fontsize=16)\n",
    "    plt.xlabel('Pozycja X [m]')\n",
    "    plt.ylabel('Pozycja Y [m]')\n",
    "    plt.axis('equal')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Brak danych\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7982c2",
   "metadata": {},
   "source": [
    "# Kalibracja parametr贸w NaSch\n",
    "\n",
    "Kalibracja parametr贸w modelu:\n",
    "- v_max - maksymalna prdko\n",
    "- p - prawdopodobiestwo losowego hamowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6ce83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wyb贸r nagrania i laneleta\\n\")\n",
    "\n",
    "print(f\"Nagranie: {TARGET_RECORDING_ID}\")\n",
    "\n",
    "if 'tracks_df' in locals() and tracks_df is not None:\n",
    "    df_target_rec = tracks_df[tracks_df['recordingId'] == TARGET_RECORDING_ID].copy()\n",
    "    print(f\"Pomiar贸w: {len(df_target_rec)}\")\n",
    "    print(f\"Pojazd贸w: {df_target_rec['trackId'].nunique()}\")\n",
    "    print(f\"Lanelet贸w: {df_target_rec['laneletId'].nunique()}\")\n",
    "    \n",
    "    lanelet_counts = df_target_rec.groupby('laneletId').size().sort_values(ascending=False)\n",
    "    print(\"\\nTop 10 lanelet贸w:\")\n",
    "    print(lanelet_counts.head(10))\n",
    "    \n",
    "    test_lanelet_id = lanelet_counts.index[0]\n",
    "    \n",
    "    test_length_m = df_target_rec[df_target_rec['laneletId'] == test_lanelet_id]['laneletLength'].max()\n",
    "    \n",
    "    print(f\"\\nWybrany lanelet: {test_lanelet_id}\")\n",
    "    print(f\"Liczba pomiar贸w: {lanelet_counts.iloc[0]}\")\n",
    "    print(f\"Dugo: {test_length_m:.1f} m\")\n",
    "else:\n",
    "    print(\"Bd: brak danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agregacja danych w biny czasowe\\n\")\n",
    "\n",
    "if 'df_target_rec' in locals() and test_lanelet_id is not None:\n",
    "    test_df = df_target_rec[df_target_rec['laneletId'] == test_lanelet_id].copy()\n",
    "        \n",
    "    FPS = 25\n",
    "    TIME_BIN = 300\n",
    "        \n",
    "    print(f\"FPS: {FPS}\")\n",
    "    print(f\"Bin czasowy: {TIME_BIN} klatek ({TIME_BIN/FPS:.1f} s)\")\n",
    "    print(f\"Dugo kom贸rki: {CELL_LENGTH_M} m\")\n",
    "\n",
    "    # --- KROK 1: Obliczanie Przepywu (Flow) za pomoc Wirtualnej Linii Pomiarowej ---\n",
    "\n",
    "    # 1a. Definicja Wirtualnej Linii Mety (np. 1 metr przed kocem laneletu)\n",
    "    S_META = test_length_m - 6.0 # Wybieramy lini pomiarow na kocu segmentu\n",
    "\n",
    "    # 1b. Sortowanie i Obliczanie Pozycji w Poprzedniej Klatce\n",
    "    # Dane musz by posortowane wedug pojazdu i czasu\n",
    "    flow_tracking_df = test_df.sort_values(['trackId', 'frame']).copy()\n",
    "\n",
    "    # Obliczanie pozycji xCenter w poprzedniej klatce DLA TEGO SAMEGO POJAZDU\n",
    "    flow_tracking_df['prev_lonLaneletPos'] = flow_tracking_df.groupby('trackId')['lonLaneletPos'].shift(1)\n",
    "\n",
    "    # 1c. Zliczanie Zdarze Przekroczenia Mety\n",
    "    # Przejcie (flow event) wystpuje, jeli:\n",
    "    # 1) W poprzedniej klatce pojazd by przed lini mety (prev_xCenter < X_META)\n",
    "    # 2) W obecnej klatce pojazd jest za lini mety (xCenter >= X_META)\n",
    "    # 3) To przejcie jest w kierunku do przodu (xCenter > prev_xCenter)\n",
    "    flow_tracking_df['flow_event'] = np.where(\n",
    "        (flow_tracking_df['prev_lonLaneletPos'] < S_META) & \n",
    "        (flow_tracking_df['lonLaneletPos'] >= S_META) &\n",
    "        (flow_tracking_df['lonLaneletPos'] > flow_tracking_df['prev_lonLaneletPos']), \n",
    "        1, \n",
    "        0\n",
    "    )\n",
    "\n",
    "    # 1d. Przypisanie Binu Czasowego do Zdarzenia Przepywu\n",
    "    flow_tracking_df['time_bin'] = (flow_tracking_df['frame'] // TIME_BIN) * TIME_BIN\n",
    "\n",
    "    # 1e. Agregacja Zdarze Przepywu do Binu\n",
    "    flow_per_bin = flow_tracking_df.groupby('time_bin')['flow_event'].sum().reset_index(name='flow_count')\n",
    "\n",
    "\n",
    "    # --- KROK 2: Przygotowanie Danych dla Gstoci (Density) (Mediana) ---\n",
    "\n",
    "    # Etap 2a: Oblicz unikalne pojazdy dla ka偶dej klatki ('frame')\n",
    "    frame_n_vehicles = test_df.groupby('frame')['trackId'].nunique().reset_index(name='n_vehicles_per_frame')\n",
    "    frame_n_vehicles['time_bin'] = (frame_n_vehicles['frame'] // TIME_BIN) * TIME_BIN\n",
    "\n",
    "    # Etap 2b: Oblicz MEDIAN N pojazd贸w dla ka偶dego binu\n",
    "    median_n_vehicles_per_bin = frame_n_vehicles.groupby('time_bin')['n_vehicles_per_frame'].mean().reset_index(name='median_n_vehicles')\n",
    "\n",
    "\n",
    "    # --- KROK 3: Iteracja i Finalne Obliczenia ---\n",
    "\n",
    "    # Utworzenie DataFrame'u do iteracji poprzez poczenie danych o medianie i flow_count\n",
    "    # U偶ywamy MEDIANY jako bazy do obliczenia Gstoci\n",
    "    # U偶ywamy FLOW_COUNT do obliczenia Przepywu\n",
    "    stats_base = pd.merge(median_n_vehicles_per_bin, flow_per_bin, on='time_bin', how='left').fillna(0)\n",
    "\n",
    "    test_df['time_bin'] = (test_df['frame'] // TIME_BIN) * TIME_BIN\n",
    "    # Potrzebujemy r贸wnie偶 redniej prdkoci dla ka偶dego binu (z caego oryginalnego df)\n",
    "    avg_speed_per_bin = test_df.groupby('time_bin')['lonVelocity'].mean().reset_index(name='avg_speed_m_s')\n",
    "    stats_base = pd.merge(stats_base, avg_speed_per_bin, on='time_bin', how='left')\n",
    "\n",
    "\n",
    "    time_duration_s = TIME_BIN / FPS\n",
    "    # cells_in_lanelet = test_length_m / CELL_LENGTH_M\n",
    "\n",
    "    segment_stats = []\n",
    "\n",
    "    for index, row in stats_base.iterrows():\n",
    "        \n",
    "        # Gsto (k) w jednostkach NaSch [pojazdy/kom贸rk]\n",
    "        occupancy = (row['median_n_vehicles'] / test_length_m) * 1000\n",
    "            \n",
    "        # Przepyw (q) [pojazdy/s]\n",
    "        # Liczba Zliczonych Przej (flow_count) podzielona przez Czas Trwania Binu\n",
    "        flow = (row['flow_count'] / time_duration_s)  * 3600\n",
    "            \n",
    "        segment_stats.append({\n",
    "            'time_bin': row['time_bin'],\n",
    "            'time_s': row['time_bin'] / FPS,\n",
    "            'n_vehicles_median': row['median_n_vehicles'],\n",
    "            'flow_count_total': row['flow_count'], # Dodatkowa informacja o surowej liczbie przej\n",
    "            'avg_speed_m_s': row['avg_speed_m_s'],\n",
    "            'density': occupancy,  # pojazdy/kom贸rk (u偶ywa mediany)\n",
    "            'flow': flow  # pojazdy/s (u偶ywa zliczonych przej)\n",
    "        })\n",
    "        \n",
    "    segment_stats = pd.DataFrame(segment_stats)\n",
    "        \n",
    "    print(f\"\\nBin贸w czasowych: {len(segment_stats)}\")\n",
    "    print(\"\\nStatystyki:\")\n",
    "    print(segment_stats.describe())\n",
    "    print(\"\\nPierwsze 5 bin贸w:\")\n",
    "    # Wywietlamy flow_count_total, aby weryfikowa poprawno oblicze\n",
    "    print(segment_stats[['time_s', 'n_vehicles_median', 'flow_count_total', 'flow', 'density', 'avg_speed_m_s']].head())\n",
    "else:\n",
    "    print(\"Bd: brak danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Diagram fundamentalny\\n\")\n",
    "\n",
    "SIMULATION_FILE_PATH = '../data/nasch_sim_K_Q.csv'\n",
    "try:\n",
    "    sim_df = pd.read_csv(SIMULATION_FILE_PATH)\n",
    "    # Zmieniamy nazwy kolumn, by pasoway do reszty kodu:\n",
    "    K_sim = sim_df['Density_K_poj_km']\n",
    "    Q_sim = sim_df['Flow_Q_poj_h']\n",
    "    \n",
    "    # Pr贸ba odczytania parametr贸w symulacji do etykiety\n",
    "    V_max_sim = sim_df['V_max_sim'].iloc[0] if 'V_max_sim' in sim_df.columns else '?'\n",
    "    P_sim = sim_df['P_sim'].iloc[0] if 'P_sim' in sim_df.columns else '?'\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"锔 Bd: Plik symulacji nie zosta znaleziony pod cie偶k: {SIMULATION_FILE_PATH}\")\n",
    "    sim_df = None\n",
    "except Exception as e:\n",
    "    print(f\"锔 Bd podczas wczytywania pliku symulacji: {e}\")\n",
    "    sim_df = None\n",
    "\n",
    "if 'segment_stats' in locals() and segment_stats is not None:\n",
    "    # x_min = 0 \n",
    "    x_min = segment_stats['density'].min() * 0.95\n",
    "    # U偶ywamy .max() z kolumny gstoci i dodajemy 5% marginesu\n",
    "    x_max = segment_stats['density'].max() * 1.05\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    # Dane Rzeczywiste (punkty kolorowane prdkoci)\n",
    "    axes[0].scatter(segment_stats['density'], segment_stats['flow'], \n",
    "                    alpha=0.6, s=50, \n",
    "                    c=segment_stats['avg_speed_m_s'], cmap='viridis', \n",
    "                    label='Dane Rzeczywiste')\n",
    "    \n",
    "    # --- DODANIE LINII TRENDU DLA DANYCH RZECZYWISTYCH ---\n",
    "    \n",
    "    # Usuwamy wiersze z zerowym przepywem (czsto szum w danych)\n",
    "    real_data_for_fit = segment_stats[(segment_stats['flow'] > 50) & (segment_stats['density'] > 0)].copy()\n",
    "    \n",
    "    if len(real_data_for_fit) > 3:\n",
    "        # Dopasowanie wielomianu 2. stopnia (parabola) do danych rzeczywistych\n",
    "        K_real = real_data_for_fit['density'].values\n",
    "        Q_real = real_data_for_fit['flow'].values\n",
    "        \n",
    "        # Obliczanie wsp贸czynnik贸w regresji\n",
    "        coeffs_real = np.polyfit(K_real, Q_real, 2)\n",
    "        poly_real = np.poly1d(coeffs_real)\n",
    "        \n",
    "        # Generowanie punkt贸w dla krzywej\n",
    "        K_range = np.linspace(K_real.min(), K_real.max(), 100)\n",
    "        Q_fit_real = poly_real(K_range)\n",
    "        \n",
    "        axes[0].plot(K_range, Q_fit_real, color='darkgreen', linestyle='-', linewidth=2, \n",
    "                     label='Trend Rzeczywisty (Fit 2. st.)', alpha=0.7)\n",
    "    \n",
    "    # DODANIE DANYCH SYMULACYJNYCH\n",
    "    if sim_df is not None:\n",
    "        axes[0].scatter(K_sim, Q_sim, \n",
    "                        alpha=0.9, s=70, \n",
    "                        c='red', marker='o', edgecolors='black', \n",
    "                        label=f'Symulacja NaSch (Vmax={V_max_sim}, P={P_sim:.3f})')\n",
    "        \n",
    "        # --- DODANIE LINII TRENDU DLA SYMULACJI ---\n",
    "        \n",
    "        # Dopasowanie wielomianu 2. stopnia do danych symulacji\n",
    "        K_sim_arr = K_sim.values\n",
    "        Q_sim_arr = Q_sim.values\n",
    "        \n",
    "        # Wybieramy tylko punkty, kt贸re nie s zerowe (zator)\n",
    "        sim_data_for_fit = sim_df[sim_df['Flow_Q_poj_h'] > 10].copy() \n",
    "\n",
    "        if len(sim_data_for_fit) > 3:\n",
    "            coeffs_sim = np.polyfit(sim_data_for_fit['Density_K_poj_km'], sim_data_for_fit['Flow_Q_poj_h'], 2)\n",
    "            poly_sim = np.poly1d(coeffs_sim)\n",
    "            \n",
    "            K_range_sim = np.linspace(sim_data_for_fit['Density_K_poj_km'].min(), sim_data_for_fit['Density_K_poj_km'].max(), 100)\n",
    "            Q_fit_sim = poly_sim(K_range_sim)\n",
    "            \n",
    "            # axes[0].plot(K_range_sim, Q_fit_sim, color='purple', linestyle='--', linewidth=2, \n",
    "            #              label='Trend Symulacji (Fit 2. st.)', alpha=0.9)\n",
    "\n",
    "\n",
    "    # DYNAMICZNE OGRANICZENIE OSI POZIOMEJ (X)\n",
    "    # axes[0].set_xlim(x_min, x_max)\n",
    "\n",
    "    axes[0].set_xlabel('Gsto K [pojazdy/km]')\n",
    "    axes[0].set_ylabel('Przepyw Q [pojazdy/h]')\n",
    "    axes[0].set_title('Diagram Fundamentalny (Flow vs Density)')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].legend(loc='upper right')\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # 2. SPEED vs DENSITY (Mo偶na tu te偶 doda fit, ale zostawiamy tylko punkty dla uproszczenia)\n",
    "    # ------------------------------------------------\n",
    "    \n",
    "    axes[1].scatter(segment_stats['density'], segment_stats['avg_speed_m_s'], \n",
    "                    alpha=0.6, s=50, c=segment_stats['avg_speed_m_s'], cmap='viridis')\n",
    "    # axes[1].set_xlim(x_min, x_max) \n",
    "    axes[1].set_xlabel('Gsto K [pojazdy/km]')\n",
    "    axes[1].set_ylabel('rednia prdko [m/s]')\n",
    "    axes[1].set_title('Prdko vs Gsto')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # 3. TIME EVOLUTION (Bez zmian)\n",
    "    # ------------------------------------------------\n",
    "    \n",
    "    ax3 = axes[2]\n",
    "    ax3_twin = ax3.twinx()\n",
    "    \n",
    "    line1 = ax3.plot(segment_stats['time_s'], segment_stats['density'], \n",
    "                      'b-', label='Gsto', linewidth=2)\n",
    "    line2 = ax3_twin.plot(segment_stats['time_s'], segment_stats['avg_speed_m_s'], \n",
    "                          'r-', label='Prdko', linewidth=2)\n",
    "    \n",
    "    ax3.set_xlabel('Czas (s)')\n",
    "    ax3.set_ylabel('Gsto (pojazdy/km)', color='b')\n",
    "    ax3_twin.set_ylabel('Prdko (m/s)', color='r')\n",
    "    ax3.set_title('Ewolucja w czasie')\n",
    "    ax3.tick_params(axis='y', labelcolor='b')\n",
    "    ax3_twin.tick_params(axis='y', labelcolor='r')\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    lines = line1 + line2\n",
    "    labels = [l.get_label() for l in lines]\n",
    "    ax3.legend(lines, labels, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nMax gsto: {segment_stats['density'].max():.3f}\")\n",
    "    print(f\"Max przepyw: {segment_stats['flow'].max():.6f}\")\n",
    "    print(f\"rednia prdko: {segment_stats['avg_speed_m_s'].mean():.2f} m/s\")\n",
    "    print(f\"Max prdko: {segment_stats['avg_speed_m_s'].max():.2f} m/s\")\n",
    "else:\n",
    "    print(\"Bd: brak danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# --- KROK 1: Upewnienie si, 偶e dane i fit istniej ---\n",
    "\n",
    "if sim_df is not None and 'poly_real' in locals():\n",
    "    \n",
    "    # ----------------------------------------------------\n",
    "    # Walidacja Modelu Symulacyjnego (NaSch) vs Dane Rzeczywiste\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    # 1. Przygotowanie danych symulacyjnych\n",
    "    # Por贸wnujemy przepyw Q symulacji z teoretycznym Q obliczonym z fitu danych rzeczywistych\n",
    "    K_sim_arr = K_sim.values # Gsto symulacji\n",
    "    Q_sim_arr = Q_sim.values # Przepyw symulacji\n",
    "    \n",
    "    # 2. Obliczanie przepywu referencyjnego (Q_ref)\n",
    "    # Obliczamy, jaki przepyw P_ref powinien mie dla danej gstoci K_sim, \n",
    "    # bazujc na dopasowanej krzywej (poly_real) danych rzeczywistych.\n",
    "    \n",
    "    # Zabezpieczenie: Przycinamy K_sim do zakresu, w kt贸rym zosta wykonany fit_real\n",
    "    k_min_fit = real_data_for_fit['density'].min()\n",
    "    k_max_fit = real_data_for_fit['density'].max()\n",
    "\n",
    "    # Filtrujemy punkty symulacji, kt贸re s poza zakresem pomiarowym danych rzeczywistych\n",
    "    valid_indices = (K_sim_arr >= k_min_fit) & (K_sim_arr <= k_max_fit)\n",
    "    \n",
    "    K_sim_valid = K_sim_arr[valid_indices]\n",
    "    Q_sim_valid = Q_sim_arr[valid_indices]\n",
    "    \n",
    "    if len(Q_sim_valid) == 0:\n",
    "        print(\"\\n锔 Nie mo偶na obliczy bd贸w: Brak punkt贸w symulacji w zakresie gstoci danych rzeczywistych.\")\n",
    "    else:\n",
    "        # Obliczanie wartoci referencyjnych Q na podstawie fitu rzeczywistego\n",
    "        Q_ref_real = poly_real(K_sim_valid)\n",
    "        \n",
    "        # 3. Obliczanie Bd贸w\n",
    "        \n",
    "        # RMSE: Pierwiastek ze redniej kwadrat贸w bd贸w. Mocniej karze du偶e bdy.\n",
    "        rmse = np.sqrt(mean_squared_error(Q_ref_real, Q_sim_valid))\n",
    "        \n",
    "        # MAE: rednia warto bezwzgldna bdu. Bardziej intuicyjna.\n",
    "        mae = mean_absolute_error(Q_ref_real, Q_sim_valid)\n",
    "\n",
    "        print(\"\\n===========================================\")\n",
    "        print(\" Walidacja Modelu NaSch (vs Trend Rzeczywisty)\")\n",
    "        print(\"===========================================\")\n",
    "        print(f\"Liczba por贸wnywanych punkt贸w: {len(Q_sim_valid)}\")\n",
    "        print(f\"redni Bd Kwadratowy (RMSE): **{rmse:.1f} poj/h**\")\n",
    "        print(f\"redni Bd Bezwzgldny (MAE): **{mae:.1f} poj/h**\")\n",
    "        print(\"===========================================\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nNie mo偶na obliczy bd贸w: Brak danych symulacyjnych lub brak dopasowanego trendu (poly_real).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589afaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Wyznaczenie parametr贸w v_max i p\\n\")\n",
    "\n",
    "if 'test_df' in locals() and test_df is not None:\n",
    "    \n",
    "    # v_max\n",
    "    test_df['v_nasch'] = (test_df['lonVelocity'] * TIME_STEP_S) / CELL_LENGTH_M\n",
    "    v_max_empirical_float = test_df['v_nasch'].quantile(0.95)\n",
    "    v_max = int(np.ceil(v_max_empirical_float))\n",
    "    \n",
    "    v_max_m_s = test_df['lonVelocity'].quantile(0.95)\n",
    "    \n",
    "    print(\"Kalibracja v_max:\")\n",
    "    print(f\"  95-ty percentyl: {v_max_empirical_float:.2f} kom贸rek/krok\")\n",
    "    print(f\"  v_max: {v_max} kom贸rek/krok\")\n",
    "    print(f\"  Maksymalna prdko: {v_max_m_s:.1f} m/s ({v_max_m_s * 3.6:.1f} km/h)\")\n",
    "    \n",
    "    # p\n",
    "    mean_speed = test_df['lonVelocity'].mean()\n",
    "    std_speed = test_df['lonVelocity'].std()\n",
    "    cv = std_speed / mean_speed if mean_speed > 0 else 0\n",
    "    p_estimated = np.clip(cv * 0.5, 0.05, 0.5)\n",
    "    \n",
    "    print(\"\\nKalibracja p:\")\n",
    "    print(f\"  rednia prdko: {mean_speed:.2f} m/s\")\n",
    "    print(f\"  Odchylenie standardowe: {std_speed:.2f}\")\n",
    "    print(f\"  Wsp贸czynnik zmiennoci: {cv:.3f}\")\n",
    "    print(f\"  Estymowane p: {p_estimated:.3f}\")\n",
    "    \n",
    "    # Analiza hamowania\n",
    "    ACCEL_THRESHOLD = -0.2\n",
    "    deceleration_events = (test_df['lonAcceleration'] < ACCEL_THRESHOLD).sum()\n",
    "    total_events = len(test_df) \n",
    "    p_from_deceleration = deceleration_events / total_events if total_events > 0 else 0.15\n",
    "    \n",
    "    print(f\"\\n  Analiza hamowania:\")\n",
    "    print(f\"  Zdarzenia hamowania: {deceleration_events}\")\n",
    "    print(f\"  czna liczba zdarze: {total_events}\")\n",
    "    print(f\"  p z hamowania: {p_from_deceleration:.3f}\")\n",
    "    \n",
    "    p_final = (p_estimated + p_from_deceleration) / 2\n",
    "    p_final = np.clip(p_final, 0.05, 0.5)\n",
    "    \n",
    "    print(f\"\\nFINALNE PARAMETRY:\")\n",
    "    print(f\"  v_max = {v_max} kom贸rek/krok\")\n",
    "    print(f\"  p = {p_final:.3f}\")\n",
    "    print(f\"\\nInterpretacja:\")\n",
    "    print(f\"  Max prdko: {v_max * CELL_LENGTH_M / TIME_STEP_S * 3.6:.0f} km/h\")\n",
    "    print(f\"  Hamowanie co ~{1/p_final:.1f} krok\")\n",
    "    \n",
    "    K = p_final\n",
    "else:\n",
    "    print(\"Bd: brak danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf73e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rozkady prdkoci\\n\")\n",
    "\n",
    "if 'test_df' in locals() and 'v_max' in locals():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    # Histogram m/s\n",
    "    axes[0].hist(test_df['lonVelocity'], bins=50, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    axes[0].axvline(test_df['lonVelocity'].quantile(0.95), color='red', linestyle='--', \n",
    "                    linewidth=2, label=f'95%: {test_df[\"lonVelocity\"].quantile(0.95):.1f} m/s')\n",
    "    axes[0].axvline(test_df['lonVelocity'].mean(), color='green', linestyle='--', \n",
    "                    linewidth=2, label=f'rednia: {test_df[\"lonVelocity\"].mean():.1f} m/s')\n",
    "    axes[0].set_xlabel('Prdko (m/s)')\n",
    "    axes[0].set_ylabel('Czsto')\n",
    "    axes[0].set_title('Rozkad prdkoci (dane rzeczywiste)')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Histogram jednostki NaSch\n",
    "    axes[1].hist(test_df['v_nasch'], bins=30, alpha=0.7, color='coral', edgecolor='black')\n",
    "    axes[1].axvline(v_max, color='red', linestyle='--', \n",
    "                    linewidth=2, label=f'v_max = {v_max}')\n",
    "    axes[1].axvline(test_df['v_nasch'].mean(), color='green', linestyle='--', \n",
    "                    linewidth=2, label=f'rednia: {test_df[\"v_nasch\"].mean():.2f}')\n",
    "    axes[1].set_xlabel('Prdko (kom贸rki/krok)')\n",
    "    axes[1].set_ylabel('Czsto')\n",
    "    axes[1].set_title('Rozkad prdkoci (jednostki NaSch)')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Statystyki:\")\n",
    "    print(f\"  Min: {test_df['lonVelocity'].min():.2f} m/s\")\n",
    "    print(f\"  25%: {test_df['lonVelocity'].quantile(0.25):.2f} m/s\")\n",
    "    print(f\"  Mediana: {test_df['lonVelocity'].median():.2f} m/s\")\n",
    "    print(f\"  75%: {test_df['lonVelocity'].quantile(0.75):.2f} m/s\")\n",
    "    print(f\"  95%: {test_df['lonVelocity'].quantile(0.95):.2f} m/s\")\n",
    "    print(f\"  Max: {test_df['lonVelocity'].max():.2f} m/s\")\n",
    "else:\n",
    "    print(\"Bd: brak danych\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a73d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_lane_change_params(tracks_df, cell_length_m, time_step_s):\n",
    "    \"\"\"\n",
    "    Kalibruje parametry motywacji (DV_min) i bezpieczestwa (Gap_rear) \n",
    "    dla rozszerzonego modelu NaSch.\n",
    "    \"\"\"\n",
    "    # 1. Filtrowanie danych do analizy zmian pasa (laneChange != 0)\n",
    "    # Wybieramy tylko te chwile, w kt贸rych ZMIANA PASA si odbywa lub ma zacz\n",
    "    lc_df = tracks_df[tracks_df['laneChange'] != 0].copy()\n",
    "\n",
    "    if lc_df.empty:\n",
    "        print(\"Brak zdarze zmiany pasa (laneChange != 0) w danych. U偶yto domylnych wartoci.\")\n",
    "        return {'DV_min': 2.0, 'Gap_rear_nasch': 2}\n",
    "\n",
    "\n",
    "    # --- PARAMETR 1: MOTYWACJA (DV_min w m/s) ---\n",
    "    \n",
    "    # Motywacja jest mierzona przez r贸偶nic prdkoci do samochodu prowadzcego (leadDV)\n",
    "    # w momencie podjcia decyzji. W NaSch chcemy to przeksztaci na v_nasch.\n",
    "    \n",
    "    # leadDV: R贸偶nica prdkoci midzy pojazdem prowadzcym a Twoim pojazdem (V_lead - V_self).\n",
    "    # Jeli V_lead > V_self, leadDV jest dodatnie.\n",
    "    # Jeli V_self jest hamowany przez V_lead, leadDV jest ujemne.\n",
    "    \n",
    "    # Chcemy znale藕 median |leadDV| dla wszystkich, kt贸rzy zmienili pas, \n",
    "    # gdy ich prdko bya ograniczona (leadDV < 0).\n",
    "    \n",
    "    # 1a. Filtrujemy tylko przypadki, gdy pojazd z przodu by wolniejszy (hamowa nas)\n",
    "    motivation_df = lc_df[lc_df['leadDV'] < 0].copy()\n",
    "    \n",
    "    if motivation_df.empty:\n",
    "        print(\"Brak zdarze zmiany pasa, w kt贸rych pojazd by hamowany. DV_min = 0.\")\n",
    "        dv_min_ms = 0.0\n",
    "    else:\n",
    "        # 1b. Obliczanie utraconej prdkoci (r贸偶nica prdkoci)\n",
    "        # Bierzemy median BEZWZGLDNEJ wartoci leadDV\n",
    "        dv_min_ms = motivation_df['leadDV'].abs().median()\n",
    "\n",
    "    # Przeliczenie na jednostki NaSch: (m/s * TIME_STEP_S) / CELL_LENGTH_M\n",
    "    DV_MIN_NASCH = (dv_min_ms * time_step_s) / cell_length_m\n",
    "    print(dv_min_ms)\n",
    "    # Minimalna r贸偶nica musi wynosi co najmniej 1 jednostk NaSch (np. 1 kom贸rka/krok)\n",
    "    # DV_MIN_NASCH = np.ceil(max(DV_MIN_NASCH, 0)) \n",
    "\n",
    "\n",
    "    # --- PARAMETR 2: BEZPIECZESTWO (Gap_rear) ---\n",
    "\n",
    "    # Mierzymy minimalny akceptowalny bufor (TTC lub THW) pozostawiony \n",
    "    # za zmieniajcym pas na pasie docelowym.\n",
    "    \n",
    "    # U偶ywamy kolumny 'leftRearId' lub 'rightRearId' do identyfikacji pojazdu z tyu\n",
    "    # oraz 'leadTHW' (Time Headway) dla og贸lnej charakterystyki odstp贸w czasowych.\n",
    "    \n",
    "    # Tutaj skupiamy si na TYLNYM poje藕dzie na NOWYM pasie.\n",
    "    # Niestety, EXID nie ma gotowego THW/DHW dla 'Rear' na 'Left'/'Right' pasie, \n",
    "    # wic musimy polega na og贸lnych statystykach.\n",
    "    \n",
    "    # Uproszczona kalibracja: Mierzymy minimalny akceptowalny odstp czasowy (TTC/THW)\n",
    "    # W praktyce modelu CA, minimalny bezpieczny dystans to 2 kom贸rki. \n",
    "    # Kalibrujemy to na podstawie mediany najmniejszych odstp贸w.\n",
    "    \n",
    "    # 2a. Obliczenie minimalnego akceptowalnego op贸藕nienia komfortowego (A_max_comfort)\n",
    "    # Wybieramy op贸藕nienia (ujemne lonAcceleration) z ruchu swobodnego (leadTHW > 5s) \n",
    "    # i bierzemy median tych op贸藕nie (warto bezwzgldn).\n",
    "    # To jest parametr, kt贸ry okrela maksymalne op贸藕nienie, jakie jest akceptowane\n",
    "    \n",
    "    decel_for_safety = tracks_df[\n",
    "        (tracks_df['leadTHW'] > 5) & # ruch swobodny lub minimalne oddziaywanie\n",
    "        (tracks_df['lonAcceleration'] < -0.1) \n",
    "    ]['lonAcceleration'].abs().mean()\n",
    "    \n",
    "    # Jeli nie znaleziono, u偶yj staej\n",
    "    A_MAX_COMFORT = max(decel_for_safety, 0) # m/s^2 (U偶ywamy co najmniej 1.5 m/s^2)\n",
    "    \n",
    "    # 2b. Konwersja do staej luki bezpieczestwa NaSch:\n",
    "    # W modelu CA, parametr bezpieczestwa czsto jest sta (min. luk w kom贸rkach)\n",
    "    # 2 kom贸rki to standardowa minimalna luka do bezpiecznego wjazdu.\n",
    "    GAP_REAR_NASCH = 2 # kom贸rki (Standardowa bezpieczna luka w NaSch)\n",
    "    \n",
    "    return {\n",
    "        'DV_min_nasch': DV_MIN_NASCH,\n",
    "        'DV_min_ms': dv_min_ms,\n",
    "        'Gap_rear_nasch': GAP_REAR_NASCH,\n",
    "        'A_max_comfort_m_s2': A_MAX_COMFORT\n",
    "    }\n",
    "\n",
    "\n",
    "calibration_params = calibrate_lane_change_params(tracks_df, CELL_LENGTH_M, TIME_STEP_S)\n",
    "print(\"\\n--- Parametry Zmiany Pasa (Kalibracja) ---\")\n",
    "print(f\"Motywacja (V_strat): {calibration_params['DV_min_nasch']:.1f} jednostek NaSch (co najmniej 1)\")\n",
    "print(f\"Minimalna luka z tyu (Gap_rear): {calibration_params['Gap_rear_nasch']} kom贸rki\")\n",
    "print(f\"Akceptowalne op贸藕nienie komfortowe: {calibration_params['A_max_comfort_m_s2']:.2f} m/s^2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
